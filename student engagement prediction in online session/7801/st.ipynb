{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"7801.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Items</th>\n",
       "      <th>Time_Spent_ in Course</th>\n",
       "      <th>Total_Logins</th>\n",
       "      <th>Activity_inside_content_ area</th>\n",
       "      <th>User_Activity_in_Goup</th>\n",
       "      <th>Nbre_of_clics</th>\n",
       "      <th>Nbre_of_ message_ participation</th>\n",
       "      <th>join_session</th>\n",
       "      <th>Time_Spent_on_Session_Attendence</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.506494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316754</td>\n",
       "      <td>0.370166</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.164921</td>\n",
       "      <td>0.104972</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402597</td>\n",
       "      <td>0.109859</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>0.241252</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.438156</td>\n",
       "      <td>0.285340</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168831</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.081031</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.385915</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>0.267035</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.385915</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>0.267035</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.057592</td>\n",
       "      <td>0.046041</td>\n",
       "      <td>0.032520</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.258899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.187196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Total_Items  Time_Spent_ in Course  Total_Logins  \\\n",
       "0      0.506494               1.000000      0.316754   \n",
       "1      0.194805               0.005378      0.164921   \n",
       "2      0.402597               0.109859      0.253927   \n",
       "3      0.480519               0.438156      0.285340   \n",
       "4      0.168831               0.001024      0.083770   \n",
       "..          ...                    ...           ...   \n",
       "95     0.831169               0.385915      0.204188   \n",
       "96     0.831169               0.385915      0.204188   \n",
       "97     0.116883               0.032522      0.057592   \n",
       "98     0.792208               0.258899      1.000000   \n",
       "99     0.051948               0.187196      0.000000   \n",
       "\n",
       "    Activity_inside_content_ area  User_Activity_in_Goup  Nbre_of_clics  \\\n",
       "0                        0.370166               0.097561       0.592593   \n",
       "1                        0.104972               0.024390       0.296296   \n",
       "2                        0.241252               0.008130       0.296296   \n",
       "3                        0.237569               0.097561       0.407407   \n",
       "4                        0.081031               0.406504       0.000000   \n",
       "..                            ...                    ...            ...   \n",
       "95                       0.267035               0.162602       0.481481   \n",
       "96                       0.267035               0.162602       0.481481   \n",
       "97                       0.046041               0.032520       0.259259   \n",
       "98                       1.000000               0.975610       0.777778   \n",
       "99                       0.007366               0.048780       0.000000   \n",
       "\n",
       "    Nbre_of_ message_ participation  join_session  \\\n",
       "0                          0.444444      0.555556   \n",
       "1                          0.111111      0.000000   \n",
       "2                          0.333333      0.777778   \n",
       "3                          0.333333      0.888889   \n",
       "4                          0.000000      0.333333   \n",
       "..                              ...           ...   \n",
       "95                         0.777778      1.000000   \n",
       "96                         0.777778      1.000000   \n",
       "97                         0.000000      0.444444   \n",
       "98                         0.888889      1.000000   \n",
       "99                         0.000000      0.111111   \n",
       "\n",
       "    Time_Spent_on_Session_Attendence Level  \n",
       "0                           0.466667    PE  \n",
       "1                           0.066667    NE  \n",
       "2                           0.600000    PE  \n",
       "3                           0.666667    PE  \n",
       "4                           0.400000    NE  \n",
       "..                               ...   ...  \n",
       "95                          0.466667    PE  \n",
       "96                          0.466667    PE  \n",
       "97                          0.200000    NE  \n",
       "98                          0.000000    AE  \n",
       "99                          0.000000    NE  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"Level\"] = le.fit_transform(df[\"Level\"])\n",
    "X = df.drop(\"Level\", axis=1)\n",
    "y = df[\"Level\"]\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Train and save models\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 20\u001b[0m     model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     21\u001b[0m     joblib\u001b[39m.\u001b[39mdump(model, name\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.joblib\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Sashank Sharma\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"linear\", C=1, probability=True, random_state=42, class_weight='balanced'),\n",
    "\n",
    "    \"RF\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"LR\": LogisticRegression(random_state=42),\n",
    "    \"LSTM\": load_model(\"lstm_model.h5\")\n",
    "}\n",
    "\n",
    "# Train and save models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, name+'.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c66dd9990b30a8fc788c907462f36e573f99030c558e42a50c0b45d3d52dc25c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
